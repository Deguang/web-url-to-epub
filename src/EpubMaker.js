import fs from 'fs-extra';
import path from 'path';
import { fileURLToPath } from 'url';
import { dirname } from 'path';
import * as cheerio from 'cheerio';
import WgetScraper from './WgetScraper.js';
import WgetImageDownloader from './WgetImageDownloader.js';
import EpubGen from 'epub-gen';

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

class EpubMaker {
  constructor(options = {}) {
    this.options = {
      title: 'Web Articles Collection',
      author: 'Web Scraper',
      language: 'en',
      outputDir: path.join(__dirname, '../output'),
      maxConcurrentUrls: 3, // æœ€å¤§å¹¶å‘URLæ•°
      maxConcurrentImages: 5, // æœ€å¤§å¹¶å‘å›¾ç‰‡æ•°
      batchSize: 5, // æ‰¹å¤„ç†å¤§å°
      ...options
    };
    
    this.webScraper = new WgetScraper();
    this.imageDownloader = new WgetImageDownloader();
    this.processedCount = 0;
    this.totalCount = 0;
  }

  async createEpubFromUrls(urlList) {
    try {
      await fs.ensureDir(this.options.outputDir);
      await this.imageDownloader.init();

      this.totalCount = urlList.length;
      this.processedCount = 0;

      console.log(`ğŸš€ Processing ${urlList.length} URLs with concurrent processing (max ${this.options.maxConcurrentUrls} concurrent)...`);
      
      const chapters = [];
      const allImages = [];

      // å¹¶å‘å¤„ç†URL
      const results = await this.processUrlsConcurrently(urlList);
      
      // æŒ‰åŸå§‹é¡ºåºæ•´ç†ç»“æœ
      for (let i = 0; i < results.length; i++) {
        const result = results[i];
        if (result.status === 'fulfilled' && result.value) {
          const { chapter, images } = result.value;
          chapters.push(chapter);
          allImages.push(...images);
        } else {
          console.error(`âŒ Failed to process URL ${i + 1}: ${result.reason?.message || 'Unknown error'}`);
          // æ·»åŠ é”™è¯¯ç« èŠ‚
          chapters.push({
            title: `Error: URL ${i + 1}`,
            data: `<h1>Error</h1><p>Could not process URL: ${urlList[i]}</p><p>${result.reason?.message || 'Unknown error'}</p>`,
            url: urlList[i]
          });
        }
      }

      await this.webScraper.close();

      const epubFilename = this.generateFilename();
      const epubPath = path.join(this.options.outputDir, epubFilename);

      console.log('\nGenerating EPUB...');
      console.log(`Total images collected: ${allImages.length}`);
      
      if (allImages.length > 0) {
        console.log(`Images embedded as base64 in HTML content`);
        console.log(`Image details:`);
        allImages.forEach((img, idx) => {
          console.log(`  ${idx + 1}. ${img.filename} (${img.alt || 'no alt'})`);
        });
      } else {
        console.log('No images found or processed');
      }

      // ğŸ”§ æ–°ç­–ç•¥ï¼šè®©epub-genæ­£ç¡®å¤„ç†å›¾ç‰‡è€Œä¸æ˜¯ç»•è¿‡å®ƒ
      // epub-genä¼šæ‰«æHTMLä¸­çš„srcå¹¶åœ¨imagesæ•°ç»„ä¸­æŸ¥æ‰¾åŒ¹é…çš„URL
      // æˆ‘ä»¬éœ€è¦ç¡®ä¿imagesæ•°ç»„ä¸­çš„URLä¸HTMLä¸­çš„base64 srcåŒ¹é…
      const imageFiles = [];
      for (const img of allImages) {
        if (await fs.pathExists(img.localPath)) {
          // ä¸ºæ¯ä¸ªbase64å›¾ç‰‡åˆ›å»ºå¯¹åº”çš„å›¾ç‰‡æ–‡ä»¶æ¡ç›®
          // å…³é”®æ˜¯è¦è®©epub-genèƒ½æ‰¾åˆ°åŒ¹é…çš„å›¾ç‰‡
          const absolutePath = path.resolve(img.localPath);
          const stats = await fs.stat(absolutePath);
          
          imageFiles.push({
            url: absolutePath,  // epub-genå°†ä½¿ç”¨è¿™ä¸ªè·¯å¾„è¯»å–æ–‡ä»¶
            alt: img.alt || 'Image',
            extension: path.extname(img.filename).toLowerCase().substring(1) || 'jpg',
            mediaType: this.getMimeType(img.filename)
          });
          
          console.log(`ğŸ”§ ä¸ºepub-genæ·»åŠ å›¾ç‰‡: ${absolutePath} (${stats.size} bytes)`);
        }
      }
      
      const epubOptions = {
        title: this.options.title,
        author: this.options.author,
        language: this.options.language,
        content: chapters,
        images: imageFiles,  // æä¾›å›¾ç‰‡ç»™epub-genè®©å®ƒæ­£ç¡®å¤„ç†
        output: epubPath,
        version: 3
      };
      
      console.log(`EPUB options prepared with ${imageFiles.length} image files for epub-gen`);

      await this.generateEpub(epubOptions);

      // å»¶è¿Ÿæ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œç¡®ä¿EPUBç”Ÿæˆå®Œæˆ
      setTimeout(async () => {
        try {
          await this.imageDownloader.cleanup();
          console.log('Temporary files cleaned up');
        } catch (error) {
          console.warn('Error during cleanup:', error.message);
        }
      }, 10000); // å»¶é•¿åˆ°10ç§’ç¡®ä¿epub-genå®Œå…¨å¤„ç†å®Œå›¾ç‰‡æ–‡ä»¶

      console.log(`\nEPUB generated successfully!`);
      console.log(`File: ${epubPath}`);
      console.log(`Size: ${await this.getFileSize(epubPath)}`);

      return epubPath;

    } catch (error) {
      console.error('Error creating EPUB:', error);
      await this.cleanup();
      throw error;
    }
  }

  async generateEpub(options) {
    return new Promise((resolve, reject) => {
      new EpubGen(options, options.output)
        .promise
        .then(() => {
          resolve();
        })
        .catch((error) => {
          reject(error);
        });
    });
  }

  generateFilename() {
    const timestamp = new Date().toISOString().slice(0, 19).replace(/[:-]/g, '');
    const title = this.options.title.toLowerCase().replace(/[^a-z0-9]/g, '_');
    return `${title}_${timestamp}.epub`;
  }

  async getFileSize(filePath) {
    try {
      const stats = await fs.stat(filePath);
      const fileSizeInBytes = stats.size;
      const fileSizeInMB = (fileSizeInBytes / (1024 * 1024)).toFixed(2);
      return `${fileSizeInMB} MB`;
    } catch (error) {
      return 'Unknown size';
    }
  }

  replaceImagesWithPlaceholders(html) {
    const $ = cheerio.load(html);
    
    $('img').each((i, elem) => {
      const $img = $(elem);
      const alt = $img.attr('alt') || 'Image';
      const src = $img.attr('src') || '';
      $img.replaceWith(`<p><em>[${alt}]</em></p>`);
    });
    
    return $.html();
  }

  getMimeType(filename) {
    const extension = path.extname(filename).toLowerCase().substring(1);
    const mimeTypes = {
      'jpg': 'image/jpeg',
      'jpeg': 'image/jpeg',
      'png': 'image/png',
      'gif': 'image/gif',
      'webp': 'image/webp',
      'svg': 'image/svg+xml',
      'bmp': 'image/bmp'
    };
    return mimeTypes[extension] || 'image/jpeg';
  }

  async processUrlsConcurrently(urlList) {
    const results = [];
    const { maxConcurrentUrls, batchSize } = this.options;
    
    // ä½¿ç”¨è¾ƒå°çš„æ‰¹å¤„ç†å’Œå¹¶å‘é™åˆ¶æ¥é¿å…èµ„æºè€—å°½
    const actualBatchSize = Math.min(batchSize, maxConcurrentUrls);
    
    for (let i = 0; i < urlList.length; i += actualBatchSize) {
      const batch = urlList.slice(i, i + actualBatchSize);
      console.log(`\nğŸ“¦ Processing batch ${Math.floor(i / actualBatchSize) + 1}/${Math.ceil(urlList.length / actualBatchSize)} (${batch.length} URLs)`);
      
      const batchPromises = batch.map((url, batchIndex) => 
        this.processSingleUrl(url, i + batchIndex)
      );
      
      const batchResults = await Promise.allSettled(batchPromises);
      results.push(...batchResults);
      
      // æ˜¾ç¤ºå½“å‰è¿›åº¦
      this.processedCount += batch.length;
      console.log(`âœ… Batch completed. Progress: ${this.processedCount}/${this.totalCount} URLs processed`);
      
      // åœ¨æ‰¹æ¬¡ä¹‹é—´æ·»åŠ çŸ­æš‚å»¶è¿Ÿï¼Œé¿å…è¿‡è½½
      if (i + actualBatchSize < urlList.length) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    }
    
    return results;
  }

  async processSingleUrl(url, urlIndex) {
    try {
      console.log(`\nğŸŒ [${urlIndex + 1}] Processing: ${url}`);
      const startTime = Date.now();
      
      const scrapedContent = await this.webScraper.scrapeUrl(url);
      const scrapeTime = Date.now() - startTime;
      
      let images = [];
      let processedHtml = scrapedContent.html;
      
      if (scrapedContent.images.length > 0) {
        console.log(`ğŸ“· [${urlIndex + 1}] Found ${scrapedContent.images.length} images - downloading...`);
        const imageStartTime = Date.now();
        
        const downloadedImages = await this.imageDownloader.downloadImages(
          scrapedContent.images, 
          urlIndex
        );
        
        const imageTime = Date.now() - imageStartTime;
        
        if (downloadedImages.length > 0) {
          processedHtml = await this.imageDownloader.replaceImageSources(
            processedHtml, 
            downloadedImages
          );
          
          images = downloadedImages;
          console.log(`âœ… [${urlIndex + 1}] Successfully processed ${downloadedImages.length} images in ${imageTime}ms`);
        } else {
          console.log(`âš ï¸ [${urlIndex + 1}] No images were successfully downloaded, using placeholders`);
          processedHtml = this.replaceImagesWithPlaceholders(processedHtml);
        }
      }

      const chapter = {
        title: scrapedContent.title,
        data: processedHtml,
        url: scrapedContent.url
      };

      const totalTime = Date.now() - startTime;
      console.log(`ğŸ‰ [${urlIndex + 1}] Completed in ${totalTime}ms (scrape: ${scrapeTime}ms)`);

      return { chapter, images };
    } catch (error) {
      console.error(`âŒ [${urlIndex + 1}] Error processing ${url}:`, error.message);
      throw error;
    }
  }

  async cleanup() {
    try {
      await this.webScraper.close();
      await this.imageDownloader.cleanup();
    } catch (error) {
      console.warn('Cleanup error:', error.message);
    }
  }
}

export default EpubMaker;